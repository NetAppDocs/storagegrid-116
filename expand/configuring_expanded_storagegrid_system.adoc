---
permalink: expand/configuring_expanded_storagegrid_system.html
sidebar: sidebar
keywords: expansion, configuration
summary: 'After completing an expansion, you must perform additional integration and configuration steps.'
---
= Configuring your expanded StorageGRID system
:icons: font
:imagesdir: ../media/

[.lead]
After completing an expansion, you must perform additional integration and configuration steps.

.About this task

You must complete the configuration tasks listed below for the grid nodes you are adding in your expansion. Some tasks might be optional, depending on the options selected when installing and administering your system, and how you want to configure the grid nodes added during the expansion.

.Steps

. If you added a Storage Node, complete the following configuration tasks.
+
[cols="2a,1a" options="header"]

|===
| Storage Node configuration tasks| For information
a|
Review the storage pools used in your ILM rules to ensure the new storage will be used.

 ** If you added a site, create a storage pool for the site and update ILM rules to use the new storage pool.
 ** If you added a Storage Node to an existing site, confirm that the new node uses the correct storage grade.
+
*Note:* By default, a new Storage Node is assigned to the All Storage Nodes storage grade and added to storage pools that use that grade for the site. If you want a new node to use a custom storage grade, you must assign it to the custom grade manually (*ILM* > *Storage Grades*).

a|
xref:../ilm/index.adoc[Manage objects with ILM]
a|
Verify that the Storage Node is ingesting objects.
a|
xref:verifying_storage_node_is_active.adoc[Verifying that the Storage Node is active]
a|
Rebalance erasure-coded data (only if you were unable to add the recommended number of Storage Nodes).
a|
xref:rebalancing_erasure_coded_data_after_adding_storage_nodes.adoc[Rebalancing erasure-coded data after adding Storage Nodes]
|===

. If you added a Gateway Node, complete the following configuration tasks.
+
[cols="2a,1a" options="header"]
|===
| Gateway Node configuration tasks| For information
a|
If High Availability Groups are used for client connections, add the Gateway Nodes to an HA group. Select *Configuration* > *Network Settings* > *High Availability Groups* to review the list of existing HA groups and to add the new nodes.
a|
xref:../admin/index.adoc[Administer StorageGRID]
|===

. If you added an Admin Node, complete the following configuration tasks.
+
[cols="2a,1a" options="header"]
|===
| Admin Node configuration tasks| For information
a|
If single sign-on is enabled for your StorageGRID system, you must create a relying party trust in Active Directory Federation Services (AD FS) for the new Admin Node. You cannot sign in to the node until you create this relying party trust.
a|
xref:../admin/configuring_sso.adoc[configuring single sign-on]
a|
If you plan to use the Load Balancer service on Admin Nodes, you might need to add the Admin Nodes to High Availability groups. Select *Configuration* > *Network Settings* > *High Availability Groups* to review the list of existing HA groups and to add the new nodes.
a|
xref:../admin/index.adoc[Administer StorageGRID]
a|
Optionally, copy the Admin Node database from the primary Admin Node to the expansion Admin Node if you want to keep the attribute and audit information consistent on each Admin Node.
a|
xref:copying_admin_node_database.adoc[Copying the Admin Node database]
a|
Optionally, copy the Prometheus database from the primary Admin Node to the expansion Admin Node if you want to keep the historical metrics consistent on each Admin Node.
a|
xref:copying_prometheus_metrics.adoc[Copying Prometheus metrics]
a|
Optionally, copy the existing audit logs from the primary Admin Node to the expansion Admin Node if you want to keep the historical log information consistent on each Admin Node.
a|
xref:copying_audit_logs.adoc[Copying audit logs]
a|
Optionally, configure access to the system for auditing purposes through an NFS or a CIFS file share.

*Note:* Audit export through CIFS/Samba has been deprecated and will be removed in a future StorageGRID release.
a|
xref:../admin/index.adoc[Administer StorageGRID]
a|
Optionally, change the preferred sender for notifications.    You can make the expansion Admin Node the preferred sender. Otherwise, an existing Admin Node configured as the preferred sender continues to send notifications, including AutoSupport messages, SNMP notifications, alert emails, and alarm emails (legacy system).
a|
xref:../admin/index.adoc[Administer StorageGRID]
|===

. If you added an Archive Node, complete the following configuration tasks.
+
[cols="2a,1a" options="header"]
|===
| Archive Node configuration tasks| For information
a|
Configure the Archive Node's connection to the targeted external archival storage system.    When you complete the expansion, Archive Nodes are in an alarm state until you configure connection information through the *ARC* > *Target* component.
a|
xref:../admin/index.adoc[Administer StorageGRID]
a|
Update the ILM policy to archive object data through the new Archive Node.
a|
xref:../ilm/index.adoc[Manage objects with ILM]
a|
Configure custom alarms for the attributes that are used to monitor the speed and efficiency of object data retrieval from Archive Nodes.
a|
xref:../admin/index.adoc[Administer StorageGRID]
|===

. To check if expansion nodes were added with an untrusted Client Network or to change whether a node's Client Network is untrusted or trusted, go to *Configuration* > *Network Settings* > *Untrusted Client Network*.
+
If the Client Network on the expansion node is untrusted, then connections to the node on the Client Network must be made using a load balancer endpoint. See the instructions for administering StorageGRID for more information.

. Configure the Domain Name System (DNS).
+
If you have been specifying DNS settings separately for each grid node, you must add custom per-node DNS settings for the new nodes. See information about modifying the DNS configuration for a single grid node in the recovery and maintenance instructions.
+
The best practice is for the grid-wide DNS server list to contain some DNS servers that are accessible locally from each site. If you just added a new site, add new DNS servers for the site to the grid-wide DNS configuration.
+
IMPORTANT: Provide two to six IPv4 addresses for DNS servers. You should select DNS servers that each site can access locally in the event of network islanding. This is to ensure an islanded site continues to have access to the DNS service. After configuring the grid-wide DNS server list, you can further customize the DNS server list for each node. For details, see the information about modifying the DNS configuration in the recovery and maintenance instructions.

. If you added a new site, confirm that Network Time Protocol (NTP) servers are accessible from that site.
+
IMPORTANT: Make sure that at least two nodes at each site can access at least four external NTP sources. If only one node at a site can reach the NTP sources, timing issues will occur if that node goes down. In addition, designating two nodes per site as primary NTP sources ensures accurate timing if a site is isolated from the rest of the grid.
+
For more information, see the recovery and maintenance instructions.

.Related information

xref:../ilm/index.adoc[Manage objects with ILM]

xref:verifying_storage_node_is_active.adoc[Verifying that the Storage Node is active]

xref:copying_admin_node_database.adoc[Copying the Admin Node database]

xref:copying_prometheus_metrics.adoc[Copying Prometheus metrics]

xref:copying_audit_logs.adoc[Copying audit logs]

xref:../upgrade/index.adoc[Upgrade software]

xref:../maintain/index.adoc[Maintain & recover]
